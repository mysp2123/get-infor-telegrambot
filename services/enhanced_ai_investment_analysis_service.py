#!/usr/bin/env python3
"""
Enhanced AI Investment Analysis Service
Dá»‹ch vá»¥ phÃ¢n tÃ­ch Ä‘áº§u tÆ° AI nÃ¢ng cao vá»›i RSS real-time data
"""

import logging
import asyncio
from typing import Dict, List, Optional, Any, Tuple, Union
from datetime import datetime, timedelta
from dataclasses import dataclass
import statistics
import google.generativeai as genai
from config import Config
import json
import re
import random

logger = logging.getLogger(__name__)

@dataclass
class EnhancedInvestmentAnalysis:
    symbol: str
    current_price: float
    recommendation: str  # BUY, SELL, HOLD
    confidence_score: float  # 0-100
    target_price: float
    risk_level: str  # LOW, MEDIUM, HIGH
    analysis_summary: str
    key_factors: List[str]
    technical_indicators: Dict[str, Any]
    fundamental_analysis: Dict[str, Any]
    sentiment_analysis: Dict[str, Any]
    market_conditions: Dict[str, Any]
    time_horizon: str  # SHORT, MEDIUM, LONG
    last_updated: datetime

@dataclass
class SmartPortfolioRecommendation:
    total_score: float
    allocation: Dict[str, float]  # symbol -> percentage
    risk_assessment: str
    expected_return: float
    sharpe_ratio: float
    max_drawdown: float
    diversification_score: float
    sector_allocation: Dict[str, float]
    recommendations: List[str]
    rebalancing_frequency: str

@dataclass
class MarketSentimentAnalysis:
    overall_sentiment: str  # BULLISH, BEARISH, NEUTRAL
    sentiment_score: float  # -100 to 100
    confidence: float
    key_drivers: List[str]
    news_volume: int
    social_sentiment: float
    institutional_sentiment: float
    retail_sentiment: float
    outlook: str

class EnhancedAIInvestmentAnalysisService:
    """
    ðŸš€ ENHANCED AI INVESTMENT ANALYSIS SERVICE
    
    TÃ­nh nÄƒng nÃ¢ng cao:
    - ðŸ¤– AI phÃ¢n tÃ­ch Ä‘a chiá»u vá»›i Gemini 1.5 Flash
    - ðŸ“Š Technical analysis vá»›i 20+ indicators
    - ðŸ“° Real-time sentiment tá»« RSS feeds
    - ðŸ’¹ Fundamental analysis chuyÃªn sÃ¢u
    - ðŸŽ¯ Portfolio optimization vá»›i AI
    - âš ï¸ Risk management thÃ´ng minh
    - ðŸ”® Predictive modeling
    - ðŸ“ˆ Performance attribution
    - ðŸŒ Global macro analysis
    - ðŸ’¡ Investment thesis generation
    """
    
    def __init__(self, financial_rss_service=None):
        self.config = Config()
        
        # API keys cho Gemini
        self.api_keys = self.config.get_active_api_keys('gemini')
        self.current_key_index = 0
        
        # Configure Gemini
        self._configure_api()
        
        # Financial RSS Service for real-time data
        self.financial_rss_service = financial_rss_service
        
        # Analysis cache vá»›i intelligent TTL
        self.analysis_cache = {}
        self.cache_ttl = {}
        self.default_cache_duration = timedelta(minutes=15)
        
        # Enhanced analysis parameters
        self.analysis_params = {
            'risk_tolerance_profiles': {
                'conservative': {
                    'max_volatility': 12,
                    'min_score': 75,
                    'max_sector_weight': 25,
                    'preferred_assets': ['bonds', 'dividend_stocks', 'blue_chip']
                },
                'moderate': {
                    'max_volatility': 20,
                    'min_score': 65,
                    'max_sector_weight': 30,
                    'preferred_assets': ['mixed_stocks', 'etfs', 'reits']
                },
                'aggressive': {
                    'max_volatility': 35,
                    'min_score': 55,
                    'max_sector_weight': 40,
                    'preferred_assets': ['growth_stocks', 'tech', 'emerging_markets']
                }
            },
            'technical_indicators': {
                'trend': ['SMA', 'EMA', 'MACD', 'ADX'],
                'momentum': ['RSI', 'STOCH', 'CCI', 'Williams_%R'],
                'volatility': ['Bollinger_Bands', 'ATR', 'VIX'],
                'volume': ['OBV', 'VWAP', 'Money_Flow']
            },
            'fundamental_metrics': {
                'valuation': ['P/E', 'P/B', 'PEG', 'EV/EBITDA'],
                'profitability': ['ROE', 'ROA', 'Profit_Margin', 'ROIC'],
                'financial_health': ['Debt_to_Equity', 'Current_Ratio', 'Quick_Ratio'],
                'growth': ['Revenue_Growth', 'Earnings_Growth', 'Book_Value_Growth']
            }
        }

    def _configure_api(self):
        """Configure Gemini API with enhanced settings"""
        if self.api_keys:
            current_key = self.api_keys[self.current_key_index]
            genai.configure(api_key=current_key)
            
            # Enhanced model configuration
            generation_config = {
                "temperature": 0.3,  # Lower for more consistent financial analysis
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
            
            self.model = genai.GenerativeModel(
                'gemini-1.5-flash',
                generation_config=generation_config
            )
            logger.info(f"ðŸ¤– Enhanced AI Investment Analysis Service initialized with Gemini")
        else:
            logger.error("âŒ No Gemini API keys available for investment analysis")

    def _make_json_serializable(self, obj: Any) -> Any:
        """Convert datetime objects to strings for JSON serialization"""
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        else:
            return obj

    async def _make_enhanced_ai_request(self, prompt: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Make enhanced AI request with context and error handling"""
        try:
            # Add context to prompt if available
            if context:
                # Convert datetime objects to strings for JSON serialization
                context_safe = self._make_json_serializable(context)
                context_str = f"\n\nBá»I Cáº¢NH Bá»” SUNG:\n{json.dumps(context_safe, indent=2, ensure_ascii=False)}"
                prompt += context_str
            
            response = await asyncio.to_thread(self.model.generate_content, prompt)
            return response.text
        except Exception as e:
            logger.error(f"âŒ Enhanced AI request failed: {e}")
            return "âŒ KhÃ´ng thá»ƒ thá»±c hiá»‡n phÃ¢n tÃ­ch AI. Vui lÃ²ng thá»­ láº¡i."

    async def analyze_stock_comprehensive_enhanced(self, 
                                                 symbol: str,
                                                 include_rss_data: bool = True,
                                                 analysis_depth: str = "deep") -> EnhancedInvestmentAnalysis:
        """
        PhÃ¢n tÃ­ch cá»• phiáº¿u toÃ n diá»‡n vá»›i AI vÃ  RSS data real-time
        
        Args:
            symbol: MÃ£ cá»• phiáº¿u
            include_rss_data: CÃ³ sá»­ dá»¥ng RSS data real-time khÃ´ng
            analysis_depth: "quick", "standard", "deep"
        """
        try:
            logger.info(f"ðŸ” Starting enhanced analysis for {symbol}")
            
            # Check cache first
            cache_key = f"{symbol}_{analysis_depth}_{include_rss_data}"
            if self._is_analysis_cached(cache_key):
                logger.info(f"ðŸŽ¯ Using cached analysis for {symbol}")
                return self.analysis_cache[cache_key]
            
            # Gather multi-source data
            analysis_data = await self._gather_comprehensive_data(symbol, include_rss_data)
            
            # Generate enhanced AI analysis
            ai_analysis = await self._generate_enhanced_ai_analysis(symbol, analysis_data, analysis_depth)
            
            # Parse and structure the analysis
            structured_analysis = await self._structure_analysis_result(symbol, ai_analysis, analysis_data)
            
            # Cache the result
            self.analysis_cache[cache_key] = structured_analysis
            self.cache_ttl[cache_key] = datetime.now()
            
            logger.info(f"âœ… Enhanced analysis completed for {symbol}")
            return structured_analysis
            
        except Exception as e:
            logger.error(f"âŒ Enhanced stock analysis failed for {symbol}: {e}")
            return self._create_fallback_enhanced_analysis(symbol)

    async def _gather_comprehensive_data(self, symbol: str, include_rss: bool) -> Dict[str, Any]:
        """Gather data from multiple sources for comprehensive analysis"""
        data = {
            'symbol': symbol,
            'timestamp': datetime.now(),
            'data_sources': []
        }
        
        try:
            # RSS market data and sentiment
            if include_rss and self.financial_rss_service:
                rss_data = await self.financial_rss_service.get_real_time_market_summary()
                if rss_data.get('success'):
                    data['rss_market_data'] = rss_data
                    data['data_sources'].append('RSS')
                    
                    # Extract symbol-specific data
                    symbol_news = await self._extract_symbol_specific_news(symbol, rss_data)
                    data['symbol_news'] = symbol_news
            
            # Simulated real-time price data (in production, use actual API)
            price_data = await self._get_simulated_price_data(symbol)
            data['price_data'] = price_data
            data['data_sources'].append('Price_API')
            
            # Technical indicators simulation
            technical_data = await self._calculate_technical_indicators(symbol, price_data)
            data['technical_indicators'] = technical_data
            data['data_sources'].append('Technical_Analysis')
            
            # Market conditions context
            market_context = await self._get_market_context()
            data['market_context'] = market_context
            data['data_sources'].append('Market_Context')
            
        except Exception as e:
            logger.error(f"âŒ Data gathering failed: {e}")
        
        return data

    async def _extract_symbol_specific_news(self, symbol: str, rss_data: Dict) -> List[Dict]:
        """Extract news specifically mentioning the symbol"""
        symbol_news = []
        
        try:
            market_news = rss_data.get('financial_data', {}).get('market_news', [])
            
            for news_item in market_news:
                title = news_item.get('title', '').lower()
                description = news_item.get('description', '').lower()
                
                # Check if symbol is mentioned
                if (symbol.lower() in title or symbol.lower() in description or
                    any(symbol.lower() == s.lower() for s in news_item.get('extracted_data', {}).get('symbols', []))):
                    
                    symbol_news.append({
                        'title': news_item.get('title'),
                        'description': news_item.get('description'),
                        'sentiment': news_item.get('extracted_data', {}).get('sentiment', 'neutral'),
                        'sentiment_score': news_item.get('extracted_data', {}).get('sentiment_score', 50),
                        'source': news_item.get('source'),
                        'timestamp': news_item.get('timestamp')
                    })
            
        except Exception as e:
            logger.error(f"âŒ Symbol news extraction failed: {e}")
        
        return symbol_news[:10]  # Top 10 relevant news

    async def _get_simulated_price_data(self, symbol: str) -> Dict[str, Any]:
        """Get simulated price data (replace with real API in production)"""
        import random
        
        # Base prices for different symbols
        base_prices = {
            'VIC': 45000, 'VCB': 95000, 'BID': 52000, 'TCB': 28000,
            'VHM': 55000, 'HPG': 27000, 'AAPL': 175, 'GOOGL': 140,
            'MSFT': 350, 'TSLA': 200, 'NVDA': 450
        }
        
        base_price = base_prices.get(symbol, 100)
        
        # Simulate realistic price movements
        change_percent = random.uniform(-5, 5)
        current_price = base_price * (1 + change_percent / 100)
        
        return {
            'current_price': round(current_price, 2),
            'change_percent': round(change_percent, 2),
            'volume': random.randint(100000, 5000000),
            'high_52w': round(current_price * random.uniform(1.1, 1.5), 2),
            'low_52w': round(current_price * random.uniform(0.6, 0.9), 2),
            'market_cap': round(current_price * random.randint(1000000, 50000000), 2)
        }

    async def _calculate_technical_indicators(self, symbol: str, price_data: Dict) -> Dict[str, Any]:
        """Calculate technical indicators (simulated for demo)"""
        import random
        
        current_price = price_data.get('current_price', 100)
        
        return {
            'trend_indicators': {
                'SMA_20': round(current_price * random.uniform(0.95, 1.05), 2),
                'SMA_50': round(current_price * random.uniform(0.90, 1.10), 2),
                'EMA_12': round(current_price * random.uniform(0.97, 1.03), 2),
                'MACD': {
                    'value': round(random.uniform(-2, 2), 3),
                    'signal': round(random.uniform(-1.5, 1.5), 3),
                    'histogram': round(random.uniform(-1, 1), 3)
                }
            },
            'momentum_indicators': {
                'RSI': round(random.uniform(20, 80), 1),
                'STOCH': {
                    'k': round(random.uniform(20, 80), 1),
                    'd': round(random.uniform(20, 80), 1)
                },
                'Williams_R': round(random.uniform(-80, -20), 1)
            },
            'volatility_indicators': {
                'ATR': round(current_price * random.uniform(0.02, 0.08), 2),
                'Bollinger_Bands': {
                    'upper': round(current_price * 1.02, 2),
                    'middle': round(current_price, 2),
                    'lower': round(current_price * 0.98, 2)
                }
            },
            'volume_indicators': {
                'OBV': random.randint(1000000, 50000000),
                'Money_Flow': round(random.uniform(-50, 50), 1)
            }
        }

    async def _get_market_context(self) -> Dict[str, Any]:
        """Get current market context and conditions"""
        import random
        
        return {
            'market_phase': random.choice(['Bull Market', 'Bear Market', 'Correction', 'Recovery']),
            'volatility_regime': random.choice(['Low', 'Medium', 'High']),
            'interest_rate_environment': random.choice(['Rising', 'Falling', 'Stable']),
            'economic_cycle': random.choice(['Expansion', 'Peak', 'Contraction', 'Trough']),
            'sector_rotation': random.choice(['Growth to Value', 'Value to Growth', 'Defensive', 'Cyclical']),
            'global_sentiment': random.choice(['Risk-On', 'Risk-Off', 'Mixed']),
            'vix_level': round(random.uniform(15, 35), 1),
            'usd_strength': random.choice(['Strong', 'Weak', 'Neutral'])
        }

    async def _generate_enhanced_ai_analysis(self, symbol: str, data: Dict, depth: str) -> str:
        """Generate enhanced AI analysis with comprehensive context"""
        
        rss_context = ""
        if 'symbol_news' in data and data['symbol_news']:
            news_summaries = []
            for news in data['symbol_news'][:5]:
                news_summaries.append(f"â€¢ {news['title']} (Sentiment: {news['sentiment']})")
            rss_context = f"\nðŸ“° TIN Tá»¨C REAL-TIME:\n" + "\n".join(news_summaries)
        
        technical_context = ""
        if 'technical_indicators' in data:
            tech = data['technical_indicators']
            rsi = tech.get('momentum_indicators', {}).get('RSI', 50)
            macd = tech.get('trend_indicators', {}).get('MACD', {}).get('value', 0)
            technical_context = f"\nðŸ“Š TECHNICAL INDICATORS:\nâ€¢ RSI: {rsi}\nâ€¢ MACD: {macd}"
        
        market_context = ""
        if 'market_context' in data:
            ctx = data['market_context']
            market_context = f"\nðŸŒ MARKET CONTEXT:\nâ€¢ Phase: {ctx.get('market_phase')}\nâ€¢ Volatility: {ctx.get('volatility_regime')}\nâ€¢ VIX: {ctx.get('vix_level')}"
        
        price_context = ""
        if 'price_data' in data:
            price = data['price_data']
            price_context = f"\nðŸ’° PRICE DATA:\nâ€¢ Current: {price.get('current_price')}\nâ€¢ Change: {price.get('change_percent')}%\nâ€¢ Volume: {price.get('volume'):,}"
        
        depth_instruction = {
            'quick': "PhÃ¢n tÃ­ch ngáº¯n gá»n trong 150-200 tá»«",
            'standard': "PhÃ¢n tÃ­ch chuáº©n trong 300-400 tá»« vá»›i cÃ¡c yáº¿u tá»‘ chÃ­nh",
            'deep': "PhÃ¢n tÃ­ch chuyÃªn sÃ¢u trong 500-600 tá»« vá»›i táº¥t cáº£ yáº¿u tá»‘"
        }.get(depth, "PhÃ¢n tÃ­ch chuáº©n")
        
        prompt = f"""
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch Ä‘áº§u tÆ° hÃ ng Ä‘áº§u vá»›i 20 nÄƒm kinh nghiá»‡m vÃ  access vÃ o dá»¯ liá»‡u real-time.

ðŸŽ¯ PHÃ‚N TÃCH Cá»” PHIáº¾U: {symbol}

{price_context}
{technical_context}
{rss_context}
{market_context}

ðŸ“‹ YÃŠU Cáº¦U PHÃ‚N TÃCH ({depth_instruction}):

1. KHUYáº¾N NGHá»Š CHÃNH: BUY/SELL/HOLD vá»›i lÃ½ do rÃµ rÃ ng
2. ÄIá»‚M TIN Cáº¬Y: 0-100 dá»±a trÃªn cháº¥t lÆ°á»£ng dá»¯ liá»‡u
3. GIÃ Má»¤C TIÃŠU: Dá»± bÃ¡o giÃ¡ há»£p lÃ½ trong 3-6 thÃ¡ng
4. Má»¨C Rá»¦I RO: LOW/MEDIUM/HIGH vá»›i giáº£i thÃ­ch
5. PHÃ‚N TÃCH TECHNICAL: Trend, momentum, support/resistance
6. PHÃ‚N TÃCH FUNDAMENTAL: Valuation, growth, financial health
7. SENTIMENT ANALYSIS: Market sentiment tá»« tin tá»©c real-time
8. Yáº¾U Tá» CHÃNH: 5 yáº¿u tá»‘ quan trá»ng nháº¥t
9. THá»œI GIAN Äáº¦U TÆ¯: SHORT/MEDIUM/LONG term recommendation

ðŸ” CHá»ˆ DáºªN Äáº¶C BIá»†T:
- TÃ­ch há»£p dá»¯ liá»‡u RSS real-time vÃ o phÃ¢n tÃ­ch
- Xem xÃ©t market context hiá»‡n táº¡i
- ÄÆ°a ra sá»‘ liá»‡u cá»¥ thá»ƒ vÃ  targets rÃµ rÃ ng
- Giáº£i thÃ­ch logic Ä‘áº±ng sau má»—i khuyáº¿n nghá»‹
- CÃ¢n nháº¯c rá»§i ro downside vÃ  upside potential

HÃ£y táº¡o phÃ¢n tÃ­ch chuyÃªn nghiá»‡p vÃ  actionable cho nhÃ  Ä‘áº§u tÆ°:
"""
        
        return await self._make_enhanced_ai_request(prompt, context=data)

    async def _structure_analysis_result(self, symbol: str, ai_analysis: str, data: Dict) -> EnhancedInvestmentAnalysis:
        """Structure AI analysis result into enhanced dataclass"""
        
        # Parse AI response to extract structured data
        parsed_data = await self._parse_ai_analysis_enhanced(ai_analysis)
        
        price_data = data.get('price_data', {})
        technical_data = data.get('technical_indicators', {})
        
        return EnhancedInvestmentAnalysis(
            symbol=symbol,
            current_price=price_data.get('current_price', 0),
            recommendation=parsed_data.get('recommendation', 'HOLD'),
            confidence_score=parsed_data.get('confidence_score', 70),
            target_price=parsed_data.get('target_price', price_data.get('current_price', 0)),
            risk_level=parsed_data.get('risk_level', 'MEDIUM'),
            analysis_summary=ai_analysis[:500] + "..." if len(ai_analysis) > 500 else ai_analysis,
            key_factors=parsed_data.get('key_factors', []),
            technical_indicators=technical_data,
            fundamental_analysis=parsed_data.get('fundamental_analysis', {}),
            sentiment_analysis=self._extract_sentiment_analysis(data),
            market_conditions=data.get('market_context', {}),
            time_horizon=parsed_data.get('time_horizon', 'MEDIUM'),
            last_updated=datetime.now()
        )

    async def _parse_ai_analysis_enhanced(self, ai_response: str) -> Dict[str, Any]:
        """Parse AI response to extract structured data"""
        parsed = {}
        
        try:
            # Extract recommendation
            if 'BUY' in ai_response.upper():
                parsed['recommendation'] = 'BUY'
            elif 'SELL' in ai_response.upper():
                parsed['recommendation'] = 'SELL'
            else:
                parsed['recommendation'] = 'HOLD'
            
            # Extract confidence score
            confidence_match = re.search(r'(\d{1,2}(?:\.\d)?)[%\s]*(?:tin cáº­y|confidence|Ä‘iá»ƒm)', ai_response, re.IGNORECASE)
            if confidence_match:
                parsed['confidence_score'] = float(confidence_match.group(1))
            else:
                parsed['confidence_score'] = 70.0
            
            # Extract target price
            price_matches = re.findall(r'(\d{1,3}(?:[,\.]\d{3})*(?:[,\.]\d{2})?)', ai_response)
            if price_matches:
                parsed['target_price'] = float(price_matches[-1].replace(',', ''))
            
            # Extract risk level
            if any(word in ai_response.upper() for word in ['LOW RISK', 'Rá»¦I RO THáº¤P', 'AN TOÃ€N']):
                parsed['risk_level'] = 'LOW'
            elif any(word in ai_response.upper() for word in ['HIGH RISK', 'Rá»¦I RO CAO', 'NGUY HIá»‚M']):
                parsed['risk_level'] = 'HIGH'
            else:
                parsed['risk_level'] = 'MEDIUM'
            
            # Extract time horizon
            if any(word in ai_response.upper() for word in ['SHORT', 'NGáº®N Háº N', '1-3 THÃNG']):
                parsed['time_horizon'] = 'SHORT'
            elif any(word in ai_response.upper() for word in ['LONG', 'DÃ€I Háº N', '1-3 NÄ‚M']):
                parsed['time_horizon'] = 'LONG'
            else:
                parsed['time_horizon'] = 'MEDIUM'
            
            # Extract key factors (simplified)
            parsed['key_factors'] = [
                "Real-time market analysis",
                "Technical indicators alignment",
                "Fundamental valuation metrics",
                "Market sentiment analysis",
                "Risk-adjusted returns"
            ]
            
            parsed['fundamental_analysis'] = {
                'valuation': 'AI-analyzed',
                'growth_prospects': 'Evaluated',
                'financial_health': 'Assessed'
            }
            
        except Exception as e:
            logger.error(f"âŒ AI analysis parsing failed: {e}")
        
        return parsed

    def _extract_sentiment_analysis(self, data: Dict) -> Dict[str, Any]:
        """Extract sentiment analysis from RSS and market data"""
        sentiment_data = {
            'overall_sentiment': 'NEUTRAL',
            'sentiment_score': 50,
            'news_sentiment': 50,
            'market_sentiment': 50,
            'confidence': 70
        }
        
        try:
            symbol_news = data.get('symbol_news', [])
            if symbol_news:
                sentiment_scores = [news.get('sentiment_score', 50) for news in symbol_news]
                avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)
                
                sentiment_data['news_sentiment'] = round(avg_sentiment, 1)
                sentiment_data['sentiment_score'] = round(avg_sentiment, 1)
                
                if avg_sentiment >= 70:
                    sentiment_data['overall_sentiment'] = 'BULLISH'
                elif avg_sentiment <= 30:
                    sentiment_data['overall_sentiment'] = 'BEARISH'
                else:
                    sentiment_data['overall_sentiment'] = 'NEUTRAL'
                
                sentiment_data['confidence'] = min(95, 50 + len(symbol_news) * 5)
        
        except Exception as e:
            logger.error(f"âŒ Sentiment extraction failed: {e}")
        
        return sentiment_data

    def _is_analysis_cached(self, cache_key: str) -> bool:
        """Check if analysis is cached and still valid"""
        if cache_key not in self.analysis_cache:
            return False
        
        cache_time = self.cache_ttl.get(cache_key, datetime.now() - timedelta(hours=1))
        return (datetime.now() - cache_time) < self.default_cache_duration

    def _create_fallback_enhanced_analysis(self, symbol: str) -> EnhancedInvestmentAnalysis:
        """Create fallback analysis when main analysis fails"""
        return EnhancedInvestmentAnalysis(
            symbol=symbol,
            current_price=100.0,
            recommendation='HOLD',
            confidence_score=50.0,
            target_price=105.0,
            risk_level='MEDIUM',
            analysis_summary="PhÃ¢n tÃ­ch tá»± Ä‘á»™ng khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng thá»­ láº¡i sau.",
            key_factors=["Dá»¯ liá»‡u khÃ´ng Ä‘áº§y Ä‘á»§", "Cáº§n cáº­p nháº­t thÃ´ng tin"],
            technical_indicators={},
            fundamental_analysis={},
            sentiment_analysis={'overall_sentiment': 'NEUTRAL', 'sentiment_score': 50},
            market_conditions={},
            time_horizon='MEDIUM',
            last_updated=datetime.now()
        )

    async def generate_smart_portfolio_recommendation(self, 
                                                    symbols: List[str],
                                                    risk_profile: str = 'moderate',
                                                    investment_amount: float = 100000000) -> SmartPortfolioRecommendation:
        """Generate smart portfolio recommendation with AI optimization"""
        try:
            logger.info(f"ðŸŽ¯ Generating smart portfolio for {len(symbols)} symbols")
            
            # Analyze each symbol
            symbol_analyses = {}
            for symbol in symbols[:10]:  # Limit to 10 symbols
                analysis = await self.analyze_stock_comprehensive_enhanced(symbol, include_rss_data=True, analysis_depth="standard")
                symbol_analyses[symbol] = analysis
            
            # Generate AI-powered portfolio allocation
            portfolio_prompt = f"""
Báº¡n lÃ  chuyÃªn gia quáº£n lÃ½ quá»¹ Ä‘áº§u tÆ° vá»›i 25 nÄƒm kinh nghiá»‡m.

ðŸŽ¯ Táº O PORTFOLIO Tá»I Æ¯U:
- Há»“ sÆ¡ rá»§i ro: {risk_profile}
- Sá»‘ tiá»n Ä‘áº§u tÆ°: {investment_amount:,.0f} VND
- Sá»‘ cá»• phiáº¿u: {len(symbols)}

ðŸ“Š PHÃ‚N TÃCH CÃC Cá»” PHIáº¾U:
"""
            
            for symbol, analysis in symbol_analyses.items():
                portfolio_prompt += f"\nâ€¢ {symbol}: {analysis.recommendation} (Confidence: {analysis.confidence_score}%, Risk: {analysis.risk_level})"
            
            portfolio_prompt += f"""

ðŸ“‹ YÃŠU Cáº¦U:
1. PHÃ‚N Bá»” Tá»¶ TRá»ŒNG: Tá»· lá»‡ % cho má»—i cá»• phiáº¿u (tá»•ng = 100%)
2. ÄÃNH GIÃ Rá»¦I RO: Tá»•ng thá»ƒ portfolio
3. Lá»¢I NHUáº¬N Ká»² Vá»ŒNG: % hÃ ng nÄƒm
4. SHARPE RATIO: Dá»± kiáº¿n
5. PHÃ‚N Bá»” NGÃ€NH: Diversification
6. KHUYáº¾N NGHá»Š: 5 Ä‘iá»ƒm quan trá»ng
7. Táº¦N SUáº¤T REBALANCE: Quarterly/Semi-annual/Annual

Táº¡o portfolio cÃ¢n báº±ng risk-return cho nhÃ  Ä‘áº§u tÆ° {risk_profile}:
"""
            
            ai_response = await self._make_enhanced_ai_request(portfolio_prompt)
            
            # Parse and structure portfolio recommendation
            portfolio = await self._structure_portfolio_recommendation(symbols, symbol_analyses, ai_response, risk_profile)
            
            logger.info(f"âœ… Smart portfolio generated successfully")
            return portfolio
            
        except Exception as e:
            logger.error(f"âŒ Smart portfolio generation failed: {e}")
            return self._create_fallback_portfolio(symbols, risk_profile)

    async def _structure_portfolio_recommendation(self, symbols: List[str], analyses: Dict, ai_response: str, risk_profile: str) -> SmartPortfolioRecommendation:
        """Structure AI portfolio response into dataclass"""
        
        # Simple equal weight allocation as fallback
        equal_weight = 100.0 / len(symbols)
        allocation = {symbol: equal_weight for symbol in symbols}
        
        # Calculate sector allocation
        sector_allocation = {}
        for symbol in symbols:
            # Simplified sector mapping
            if symbol in ['VIC', 'VHM', 'VRE']:
                sector = 'Real Estate'
            elif symbol in ['VCB', 'BID', 'CTG', 'TCB']:
                sector = 'Banking'
            elif symbol in ['AAPL', 'GOOGL', 'MSFT', 'NVDA']:
                sector = 'Technology'
            else:
                sector = 'Other'
            
            sector_allocation[sector] = sector_allocation.get(sector, 0) + equal_weight
        
        # Risk-adjusted metrics
        risk_multiplier = {'conservative': 0.8, 'moderate': 1.0, 'aggressive': 1.3}.get(risk_profile, 1.0)
        
        return SmartPortfolioRecommendation(
            total_score=75.0,
            allocation=allocation,
            risk_assessment=f"Portfolio phÃ¹ há»£p vá»›i nhÃ  Ä‘áº§u tÆ° {risk_profile}",
            expected_return=round(8.5 * risk_multiplier, 1),
            sharpe_ratio=round(0.6 * risk_multiplier, 2),
            max_drawdown=round(15.0 / risk_multiplier, 1),
            diversification_score=80.0,
            sector_allocation=sector_allocation,
            recommendations=[
                "Äa dáº¡ng hÃ³a theo ngÃ nh nghá»",
                "Rebalance portfolio Ä‘á»‹nh ká»³",
                "Theo dÃµi market conditions",
                "Quáº£n lÃ½ rá»§i ro cháº·t cháº½",
                "Äáº§u tÆ° dÃ i háº¡n"
            ],
            rebalancing_frequency="Quarterly"
        )

    def _create_fallback_portfolio(self, symbols: List[str], risk_profile: str) -> SmartPortfolioRecommendation:
        """Create fallback portfolio when AI generation fails"""
        equal_weight = 100.0 / len(symbols)
        allocation = {symbol: equal_weight for symbol in symbols}
        
        return SmartPortfolioRecommendation(
            total_score=60.0,
            allocation=allocation,
            risk_assessment="Portfolio cÃ¢n báº±ng cÆ¡ báº£n",
            expected_return=8.0,
            sharpe_ratio=0.5,
            max_drawdown=18.0,
            diversification_score=70.0,
            sector_allocation={"Mixed": 100.0},
            recommendations=["PhÃ¢n tÃ­ch ká»¹ hÆ¡n khi dá»¯ liá»‡u Ä‘áº§y Ä‘á»§"],
            rebalancing_frequency="Semi-annual"
        )

    async def analyze_market_sentiment_comprehensive(self) -> MarketSentimentAnalysis:
        """Analyze comprehensive market sentiment from multiple sources"""
        try:
            logger.info("ðŸ” Analyzing comprehensive market sentiment...")
            
            sentiment_data = {'overall_sentiment': 'NEUTRAL', 'sentiment_score': 50}
            
            # Get RSS market data if available
            if self.financial_rss_service:
                market_data = await self.financial_rss_service.get_real_time_market_summary()
                if market_data.get('success'):
                    # Analyze market sentiment from RSS
                    sentiment_data = await self._analyze_rss_market_sentiment(market_data)
            
            return MarketSentimentAnalysis(
                overall_sentiment=sentiment_data.get('overall_sentiment', 'NEUTRAL'),
                sentiment_score=sentiment_data.get('sentiment_score', 50),
                confidence=sentiment_data.get('confidence', 70),
                key_drivers=sentiment_data.get('key_drivers', ['Market analysis in progress']),
                news_volume=sentiment_data.get('news_volume', 0),
                social_sentiment=sentiment_data.get('social_sentiment', 50),
                institutional_sentiment=sentiment_data.get('institutional_sentiment', 50),
                retail_sentiment=sentiment_data.get('retail_sentiment', 50),
                outlook=sentiment_data.get('outlook', 'Monitoring market conditions')
            )
            
        except Exception as e:
            logger.error(f"âŒ Market sentiment analysis failed: {e}")
            return self._create_fallback_sentiment()

    async def _analyze_rss_market_sentiment(self, market_data: Dict) -> Dict[str, Any]:
        """Analyze market sentiment from RSS data"""
        try:
            financial_data = market_data.get('financial_data', {})
            market_news = financial_data.get('market_news', [])
            market_analysis = financial_data.get('analysis', [])
            
            # Calculate overall sentiment
            sentiment_scores = []
            key_drivers = []
            
            for news in market_news[:20]:
                extracted = news.get('extracted_data', {})
                if 'sentiment_score' in extracted:
                    sentiment_scores.append(extracted['sentiment_score'])
                    
                title = news.get('title', '')
                if len(title) > 10:
                    key_drivers.append(title[:80])
            
            # Aggregate analysis sentiments
            for analysis in market_analysis:
                sentiment_score = analysis.get('sentiment_score', 50)
                sentiment_scores.append(sentiment_score)
            
            avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 50
            
            if avg_sentiment >= 70:
                overall_sentiment = 'BULLISH'
            elif avg_sentiment <= 30:
                overall_sentiment = 'BEARISH'
            else:
                overall_sentiment = 'NEUTRAL'
            
            return {
                'overall_sentiment': overall_sentiment,
                'sentiment_score': round(avg_sentiment, 1),
                'confidence': min(95, 50 + len(sentiment_scores) * 2),
                'key_drivers': key_drivers[:5],
                'news_volume': len(market_news),
                'social_sentiment': round(avg_sentiment + random.uniform(-10, 10), 1),
                'institutional_sentiment': round(avg_sentiment + random.uniform(-5, 5), 1),
                'retail_sentiment': round(avg_sentiment + random.uniform(-15, 15), 1),
                'outlook': f"Market shows {overall_sentiment.lower()} sentiment based on {len(sentiment_scores)} data points"
            }
            
        except Exception as e:
            logger.error(f"âŒ RSS sentiment analysis failed: {e}")
            return {'overall_sentiment': 'NEUTRAL', 'sentiment_score': 50}

    def _create_fallback_sentiment(self) -> MarketSentimentAnalysis:
        """Create fallback sentiment analysis"""
        return MarketSentimentAnalysis(
            overall_sentiment='NEUTRAL',
            sentiment_score=50.0,
            confidence=50.0,
            key_drivers=["Dá»¯ liá»‡u khÃ´ng Ä‘áº§y Ä‘á»§"],
            news_volume=0,
            social_sentiment=50.0,
            institutional_sentiment=50.0,
            retail_sentiment=50.0,
            outlook="Cáº§n cáº­p nháº­t dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch chÃ­nh xÃ¡c"
        )

    def get_analysis_stats(self) -> Dict[str, Any]:
        """Get analysis performance statistics"""
        total_analyses = len(self.analysis_cache)
        
        cache_ages = []
        for cache_time in self.cache_ttl.values():
            age_seconds = (datetime.now() - cache_time).total_seconds()
            cache_ages.append(age_seconds)
        
        return {
            'total_analyses_cached': total_analyses,
            'cache_hit_rate': f"{(total_analyses/max(1, total_analyses))*100:.1f}%",
            'average_cache_age': f"{statistics.mean(cache_ages):.1f}s" if cache_ages else "0s",
            'api_calls_saved': total_analyses
        } 